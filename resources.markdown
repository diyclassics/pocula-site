---
layout: page
title: Resources
permalink: /resources/
---

## Online Resources

### Tools

- [LatinCy](https://huggingface.co/latincy). Pretrained NLP pipelines for Latin developed by Patrick J. Burns. POCULA uses LatinCy for Latin text processing tasks.
- [Common Corpus](https://huggingface.co/datasets/PleIAs/common_corpus). A large-scale multilingual dataset that includes digitized Latin texts. POCULA draws its source material from Common Corpus.

### Related Projects

- [Latin BERT](https://github.com/dbamman/latin-bert). A BERT language model trained on Latin texts by David Bamman.

## Select Bibliography

Below is a starter bibliography to help POCULA contributors familiarize themselves with the relevant scholarship on OCR correction and Latin NLP.

- Bamman, D., and Burns, P.J. 2020. "Latin BERT: A Contextual Language Model for Classical Philology." *arXiv preprint*. [arXiv:2009.10053](https://arxiv.org/abs/2009.10053)
- Burns, P.J. 2023. "LatinCy: Synthetic Trained Pipelines for Latin NLP." *arXiv preprint*. [arXiv:2305.04365](https://arxiv.org/abs/2305.04365)
